**epoch = (iter * batch_size) / data_size**

**transformer 需要花费更多的时间去训练**

[pytorch lightning] (https://www.pytorchlightning.ai/blog)

https://paperswithcode.com/methods/category/object-detection-models

https://jalammar.github.io/illustrated-transformer/

https://github.com/KevinMusgrave/pytorch-metric-learning

https://github.com/microsoft/computervision-recipes/blob/master/scenarios/action_recognition/01_training_introduction.ipynb

https://github.com/Shaoli-Huang/SnapMix

https://github.com/jettify/pytorch-optimizer

https://pytorch.org/assets/deep-learning/Deep-Learning-with-PyTorch.pdf

https://github.com/eriklindernoren/PyTorch-GAN

**GCNet**

GCNet 中不同query位置的attention map几乎是相同的，所以在non-local block中通过计算global的attention map以及对于所有query 位置都共享这个attention map
来进行简化。GC block和SE block的不同是SE block通过recale来对校准通道的重要性，而GC block则是通过addition来聚合所有位置的global context来获取各位置间
长距离依赖关系的信息。并且在GC block中引入了layer normalization更好的进行优化。

**VFnet**

![image](https://github.com/chang4869/deep-learning/blob/gh-pages/0.png)

The network architecture of our VFNet. The VFNet is built on the FPN (P3-P7). Its head consists of two subnetworks, one for regressing the initial bounding box and refining it, and the other for predicting the IoU-aware classification
score, based on a star-shaped bounding box feature representation (Star Dconv). H×W denotes the size of the feature map.

相比于FCOS+ATSS，vfnet移除了centerness分支， 引入了三个新的组成。分别是varifocal loss ，star-shape的bbox 特征表示, 还有bbox的提炼。
![image](https://github.com/chang4869/deep-learning/blob/gh-pages/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202020-12-29%20142647.png)

p是预测的基于IOU的分类得分(IACS), q是目标的IOU得分，对于正样本，q为生成的边界框和真实框的IOU，对于负样本，q为0。varifocal loss只减少负样本对于损失的贡献，
没有以相同的方式降低正样本的损失权重，VFnet使用9个固定采样点的特征表示边界框，用的是deformable卷积，这样能获得边界框的几何信息和它邻近的上下文信息。VFnet把bbox的提炼
当成一个残差问题来学习，对于一个初始的回归边界框(l',t',r', b')，首先提取star-shape的表示进行编码，然后学习4个距离缩放系数,来缩放距离向量，结果提炼的边界框可以表示为
(l, t, r, b) = (∆l×l’,∆t×t’, ∆r×r’, ∆b×b’)
![image](https://github.com/chang4869/deep-learning/blob/gh-pages/1.png)
L_bbox是GIOu损失， bbox'和bbox，bbox* 分别是初始的，提炼的和真实的边界框。

**deformable cnn**

可变形卷积不是对卷积核做可变形，而是通过给输入的feature map中的每个位置引入一个可学习的偏移量，对feature map做变形。首先通过对输入做卷积操作，输出通道为2xkxk,k
是卷积核的大小，乘以2是在x,y两个方向上的偏移量，得到的偏移量是小数，还要做双线性插值。可变形卷积提高了模型对于几何形变的建模能力。但是也可能引入一些无用的上下文信息
因此提出了DCNV2，通过给每个卷积核的每个采样位置分配一个可学习的权重。

